{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f79e233-f4e2-4d7b-9fd2-6ef9a7755801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, LongType\n",
    "\n",
    "KAFKA_BOOTSTRAP_SERVERS = \"kafka1:19092,kafka2:19093,kafka3:19094\"\n",
    "KAFKA_TOPIC = \"events\"\n",
    "\n",
    "\n",
    "events_schema = StructType([ \n",
    "    StructField('timestamp', StringType(), True),\n",
    "    StructField('type', StringType(), True),\n",
    "    StructField('appName', StringType(), True), \n",
    "    StructField('appInstance', StringType(), True),\n",
    "    StructField('appID', StringType(), True),\n",
    "    StructField('probeID', StringType(), True),\n",
    "    StructField('eventID', StringType(), True),\n",
    "    StructField('correletionID', StringType(), True),\n",
    "    StructField('locationID', StringType(), True),\n",
    "    StructField('transactionStart', StringType(), True), \n",
    "    StructField('transactionEnd', StringType(), True), \n",
    "    StructField('transactionDuration', StringType(), True), \n",
    "    StructField('clientIPAddress', StringType(), True),\n",
    "    StructField('clientPort', StringType(), True), \n",
    "    StructField('serverIPAddress', StringType(), True), \n",
    "    StructField('serverPort', StringType(), True), \n",
    "    StructField('ipProtocol', StringType(), True), \n",
    "    StructField('category', StringType(), True), \n",
    "    StructField('bytesFromClient', StringType(), True), \n",
    "    StructField('bytesToClient', StringType(), True), \n",
    "    StructField('bytesFromServer', StringType(), True), \n",
    "    StructField('bytesToServer', StringType(), True), \n",
    "    StructField('subscriberID', StringType(), True), \n",
    "    StructField('applicationProtocol', StringType(), True), \n",
    "    StructField('applicationName', StringType(), True), \n",
    "    StructField('domain', StringType(), True), \n",
    "    StructField('deviceType', StringType(), True), \n",
    "    StructField('networkType', StringType(), True), \n",
    "    StructField('contentType', StringType(), True), \n",
    "    StructField('lostBytesClient', StringType(), True), \n",
    "    StructField('lostBytesServer', StringType(), True), \n",
    "    StructField('srttMsClient', StringType(), True), \n",
    "    StructField('srttMsServer', StringType(), True), \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"stream-from-Kafka\") \\\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 4) \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reduce logging\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "df = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVERS) \\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634a3cb8-66ed-4ee5-a53c-0c6a7869ff6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse value from binay to string\n",
    "json_df = df.selectExpr(\"cast(value as string) as value\")\n",
    "\n",
    "# Apply Schema to JSON value column and expand the value\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "json_expanded_df = json_df.withColumn(\"value\", from_json(json_df[\"value\"], events_schema)).select(\"value.*\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa3ecf-b19a-49bd-8916-3c770cf23a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the output to console sink to check the output\n",
    "writing_df = json_expanded_df.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "    \n",
    "# Start the streaming application to run until the following happens\n",
    "# 1. Exception in the running program\n",
    "# 2. Manual Interruption\n",
    "writing_df.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429b305-365c-43cc-9bb5-a2ead1f1e217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
